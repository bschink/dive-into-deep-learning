{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f66f527",
   "metadata": {},
   "source": [
    "# 8.2. Networks Using Blocks (VGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15dda3",
   "metadata": {},
   "source": [
    "## ðŸ“˜ Code Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266de43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from utils import Classifier\n",
    "from utils import Trainer\n",
    "from dataloaders import FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c445f",
   "metadata": {},
   "source": [
    "### 8.2.1. VGG Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefb512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed848501",
   "metadata": {},
   "source": [
    "### 8.2.2. VGG Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54b026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(module):\n",
    "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "class VGG(Classifier):\n",
    "    def __init__(self, arch, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        conv_blks = []\n",
    "        for (num_convs, out_channels) in arch:\n",
    "            conv_blks.append(vgg_block(num_convs, out_channels))\n",
    "        self.net = nn.Sequential(\n",
    "            *conv_blks, nn.Flatten(),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.LazyLinear(num_classes))\n",
    "        self.net.apply(init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d412e2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten output shape:\t torch.Size([1, 25088])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 4096])\n",
      "ReLU output shape:\t torch.Size([1, 4096])\n",
      "Dropout output shape:\t torch.Size([1, 4096])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).layer_summary(\n",
    "    (1, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75e25d",
   "metadata": {},
   "source": [
    "### 8.2.3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2534199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1096bc4a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benediktschink/VSCode/dive-into-deep-learning/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/benediktschink/VSCode/dive-into-deep-learning/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1627, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_fork.py\", line 41, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py\", line 1148, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py\", line 398, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/Users/benediktschink/VSCode/dive-into-deep-learning/venv/lib/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 71164) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m data = FashionMNIST(batch_size=\u001b[32m64\u001b[39m, resize=(\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m))\n\u001b[32m      4\u001b[39m model.apply_init([\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(data.get_dataloader(\u001b[38;5;28;01mTrue\u001b[39;00m)))[\u001b[32m0\u001b[39m]], init_cnn)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/dive-into-deep-learning/notebooks/chapter_08_modern_convolutional_neural_networks/../../utils/trainer.py:35\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, data)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.val_batch_idx = \u001b[32m0\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_epochs):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/dive-into-deep-learning/notebooks/chapter_08_modern_convolutional_neural_networks/../../utils/trainer.py:45\u001b[39m, in \u001b[36mTrainer.fit_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mself\u001b[39m.model.train()\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_dataloader:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mself\u001b[39m.optim.zero_grad()\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/dive-into-deep-learning/notebooks/chapter_08_modern_convolutional_neural_networks/../../utils/module.py:41\u001b[39m, in \u001b[36mModule.training_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[32m     40\u001b[39m     l = \u001b[38;5;28mself\u001b[39m.loss(\u001b[38;5;28mself\u001b[39m(*batch[:-\u001b[32m1\u001b[39m]), batch[-\u001b[32m1\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mloss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m l\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VSCode/dive-into-deep-learning/notebooks/chapter_08_modern_convolutional_neural_networks/../../utils/module.py:35\u001b[39m, in \u001b[36mModule.plot\u001b[39m\u001b[34m(self, key, value, train)\u001b[39m\n\u001b[32m     32\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.trainer.epoch + \u001b[32m1\u001b[39m\n\u001b[32m     33\u001b[39m     n = \u001b[38;5;28mself\u001b[39m.trainer.num_val_batches / \\\n\u001b[32m     34\u001b[39m         \u001b[38;5;28mself\u001b[39m.plot_valid_per_epoch\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28mself\u001b[39m.board.draw(x, \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.detach().numpy(),\n\u001b[32m     36\u001b[39m                 (\u001b[33m'\u001b[39m\u001b[33mtrain_\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mval_\u001b[39m\u001b[33m'\u001b[39m) + key,\n\u001b[32m     37\u001b[39m                 every_n=\u001b[38;5;28mint\u001b[39m(n))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n",
    "trainer = Trainer(max_epochs=10, num_gpus=1)\n",
    "data = FashionMNIST(batch_size=64, resize=(224, 224))\n",
    "model.apply_init([next(iter(data.get_dataloader(True)))[0]], init_cnn)\n",
    "trainer.fit(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
